{"uid":"450d76015748d7bf","name":"Validate Council Output [SouthOxfordshireCouncil-None-None]","fullName":"features/validate_council_outputs.feature:Validate Council Output","historyId":"7f57931d644fea4dd7a0419f9995c47e","time":{"start":1704704216957,"stop":1704704220192,"duration":3235},"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fdb498e6830>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=265859142\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fdb49e3b400>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fdb49190250>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fdb498e6830>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=265859142\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fdb498e6830>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=265859142\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fdb49e3b400>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fdb49190250>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fdb498e6830>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=265859142\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","steps":[{"name":"Given the council: SouthOxfordshireCouncil","time":{"start":1704704216957,"stop":1704704216958,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"When we scrape the data from SouthOxfordshireCouncil using None and the None is set","time":{"start":1704704216958,"stop":1704704220192,"duration":3234},"status":"failed","statusMessage":"Error parsing bin data: list index out of range","statusTrace":"ValueError: Error parsing bin data: list index out of range\n","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":0,"hasContent":true,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":2,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"host","value":"fv-az659-507"},{"name":"thread","value":"2717-MainThread"},{"name":"framework","value":"pytest-bdd"},{"name":"language","value":"cpython3"},{"name":"feature","value":"Test each council output matches expected results"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"council","value":"SouthOxfordshireCouncil"},{"name":"selenium_mode","value":"None"},{"name":"selenium_url","value":"None"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[],"flaky":false}],"history":{"statistic":{"failed":39,"broken":0,"skipped":0,"passed":106,"unknown":0,"total":145},"items":[{"uid":"f45ed677ebae8868","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1441//#testresult/f45ed677ebae8868","status":"failed","statusDetails":"ValueError: Error parsing bin data: list index out of range","time":{"start":1704673873202,"stop":1704673878136,"duration":4934}},{"uid":"a8fa08c4557b7c9b","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1426//#testresult/a8fa08c4557b7c9b","status":"passed","time":{"start":1704615551652,"stop":1704615555793,"duration":4141}},{"uid":"935d31e7a586965","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1423//#testresult/935d31e7a586965","status":"passed","time":{"start":1704614875626,"stop":1704614878569,"duration":2943}},{"uid":"50cbecbc7c98b65f","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1420//#testresult/50cbecbc7c98b65f","status":"passed","time":{"start":1704587601856,"stop":1704587605425,"duration":3569}},{"uid":"d7410542d4ea2ec9","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1413//#testresult/d7410542d4ea2ec9","status":"passed","time":{"start":1704542860636,"stop":1704542864641,"duration":4005}},{"uid":"8c8944b548c155","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1408//#testresult/8c8944b548c155","status":"passed","time":{"start":1704496321306,"stop":1704496325789,"duration":4483}},{"uid":"54d1cac52f24af94","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1406//#testresult/54d1cac52f24af94","status":"passed","time":{"start":1704453571836,"stop":1704453576010,"duration":4174}},{"uid":"51fe50946132f1a9","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1407//#testresult/51fe50946132f1a9","status":"passed","time":{"start":1704453544022,"stop":1704453547138,"duration":3116}},{"uid":"82794784344352d2","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1405//#testresult/82794784344352d2","status":"passed","time":{"start":1704452767419,"stop":1704452770457,"duration":3038}},{"uid":"f832392c4ea281eb","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1400//#testresult/f832392c4ea281eb","status":"passed","time":{"start":1704443891224,"stop":1704443894642,"duration":3418}},{"uid":"7d66128b6a1a87f8","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1399//#testresult/7d66128b6a1a87f8","status":"passed","time":{"start":1704443438354,"stop":1704443441789,"duration":3435}},{"uid":"eddcfd2522cc82f4","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1397//#testresult/eddcfd2522cc82f4","status":"passed","time":{"start":1704442611559,"stop":1704442614727,"duration":3168}},{"uid":"383110e68a47476f","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1390//#testresult/383110e68a47476f","status":"passed","time":{"start":1704417644674,"stop":1704417647974,"duration":3300}},{"uid":"9d13a09615e3c736","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1379//#testresult/9d13a09615e3c736","status":"passed","time":{"start":1704406138636,"stop":1704406142995,"duration":4359}},{"uid":"5a869f970a7d3ba3","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1378//#testresult/5a869f970a7d3ba3","status":"passed","time":{"start":1704406076983,"stop":1704406080095,"duration":3112}},{"uid":"39d1ff568c2b6272","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1376//#testresult/39d1ff568c2b6272","status":"passed","time":{"start":1704398927694,"stop":1704398930801,"duration":3107}},{"uid":"92bd1a38b0e30461","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1375//#testresult/92bd1a38b0e30461","status":"passed","time":{"start":1704398855470,"stop":1704398858938,"duration":3468}},{"uid":"dcc344d0d3df8a2a","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1373//#testresult/dcc344d0d3df8a2a","status":"passed","time":{"start":1704388440563,"stop":1704388444983,"duration":4420}},{"uid":"a8e8c90e1354f8dc","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1372//#testresult/a8e8c90e1354f8dc","status":"passed","time":{"start":1704388387341,"stop":1704388391092,"duration":3751}},{"uid":"1690d2fd7071b305","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1369//#testresult/1690d2fd7071b305","status":"passed","time":{"start":1704378494134,"stop":1704378497499,"duration":3365}}]},"tags":[]},"source":"450d76015748d7bf.json","parameterValues":["SouthOxfordshireCouncil","None","None"]}