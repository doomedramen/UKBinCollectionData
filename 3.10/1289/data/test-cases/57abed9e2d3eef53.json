{"uid":"57abed9e2d3eef53","name":"Validate Council Output [SouthOxfordshireCouncil-None-None]","fullName":"features/validate_council_outputs.feature:Validate Council Output","historyId":"7f57931d644fea4dd7a0419f9995c47e","time":{"start":1703381148102,"stop":1703381152276,"duration":4174},"status":"failed","statusMessage":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fa8b24b5d50>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1343967379\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': [{'collectionDate': '22/12/2024', 'type': 'Grey bin, small electrical items and food bin'}]}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n>                   datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata_string = 'Your usual collection day is different this weekTuesday 2 January 2023'\nformat = '%A %d %B %Y'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fa8c6368670>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fa8b279c4c0>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:75: in scrape_step\n    raise (err)\nuk_bin_collection/tests/step_defs/test_validate_council.py:71: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:82: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:69: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:69: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fa8b24b5d50>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1343967379\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': [{'collectionDate': '22/12/2024', 'type': 'Grey bin, small electrical items and food bin'}]}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n                    datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n                bin_type = str.capitalize(bin_info[1].strip())\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:68: ValueError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"status":"failed","statusMessage":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fa8b24b5d50>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1343967379\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': [{'collectionDate': '22/12/2024', 'type': 'Grey bin, small electrical items and food bin'}]}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n>                   datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata_string = 'Your usual collection day is different this weekTuesday 2 January 2023'\nformat = '%A %d %B %Y'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fa8c6368670>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fa8b279c4c0>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:75: in scrape_step\n    raise (err)\nuk_bin_collection/tests/step_defs/test_validate_council.py:71: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:82: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:69: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:69: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fa8b24b5d50>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1343967379\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': [{'collectionDate': '22/12/2024', 'type': 'Grey bin, small electrical items and food bin'}]}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n                    datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n                bin_type = str.capitalize(bin_info[1].strip())\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:68: ValueError","steps":[{"name":"Given the council: SouthOxfordshireCouncil","time":{"start":1703381148102,"stop":1703381148103,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"When we scrape the data from SouthOxfordshireCouncil using None and the None is set","time":{"start":1703381148103,"stop":1703381152276,"duration":4173},"status":"failed","statusMessage":"Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":0,"hasContent":true,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":2,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"host","value":"fv-az1110-626"},{"name":"thread","value":"2781-MainThread"},{"name":"framework","value":"pytest-bdd"},{"name":"language","value":"cpython3"},{"name":"feature","value":"Test each council output matches expected results"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"council","value":"SouthOxfordshireCouncil"},{"name":"selenium_mode","value":"None"},{"name":"selenium_url","value":"None"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[],"flaky":false}],"history":{"statistic":{"failed":5,"broken":0,"skipped":0,"passed":79,"unknown":0,"total":84},"items":[{"uid":"7bc07fe90600c038","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1287//#testresult/7bc07fe90600c038","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703294171388,"stop":1703294174873,"duration":3485}},{"uid":"c9caf2b53ee5feed","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1282//#testresult/c9caf2b53ee5feed","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703207946936,"stop":1703207951305,"duration":4369}},{"uid":"54d4930ace8b216a","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1281//#testresult/54d4930ace8b216a","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703121579048,"stop":1703121582193,"duration":3145}},{"uid":"89dc65b6670e3bd","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1280//#testresult/89dc65b6670e3bd","status":"passed","time":{"start":1703034414798,"stop":1703034419476,"duration":4678}},{"uid":"758b6a9e82958793","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1279//#testresult/758b6a9e82958793","status":"passed","time":{"start":1703024993793,"stop":1703024996737,"duration":2944}},{"uid":"187b6336663a9e15","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1276//#testresult/187b6336663a9e15","status":"passed","time":{"start":1702948810335,"stop":1702948814124,"duration":3789}},{"uid":"57f5e63ee98ac7ee","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1275//#testresult/57f5e63ee98ac7ee","status":"passed","time":{"start":1702862458951,"stop":1702862462563,"duration":3612}},{"uid":"467cf631e64568e0","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1274//#testresult/467cf631e64568e0","status":"passed","time":{"start":1702860084222,"stop":1702860088740,"duration":4518}},{"uid":"e229854269b5f098","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1272//#testresult/e229854269b5f098","status":"passed","time":{"start":1702843634406,"stop":1702843637873,"duration":3467}},{"uid":"31e3f9ebf503240","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1270//#testresult/31e3f9ebf503240","status":"passed","time":{"start":1702809491923,"stop":1702809495930,"duration":4007}},{"uid":"58c7e43a943f48ff","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1247//#testresult/58c7e43a943f48ff","status":"passed","time":{"start":1702657282849,"stop":1702657285972,"duration":3123}},{"uid":"da16c3583f0ad143","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1244//#testresult/da16c3583f0ad143","status":"passed","time":{"start":1702603256317,"stop":1702603259880,"duration":3563}},{"uid":"bf60b46ff5016658","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1243//#testresult/bf60b46ff5016658","status":"passed","time":{"start":1702540119730,"stop":1702540122768,"duration":3038}},{"uid":"d5d4e31ed7ea31e2","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1241//#testresult/d5d4e31ed7ea31e2","status":"passed","time":{"start":1702516901113,"stop":1702516905149,"duration":4036}},{"uid":"e41d4146969bf10f","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1238//#testresult/e41d4146969bf10f","status":"passed","time":{"start":1702447592652,"stop":1702447596892,"duration":4240}},{"uid":"ec3d1689f1721de5","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1237//#testresult/ec3d1689f1721de5","status":"passed","time":{"start":1702447507976,"stop":1702447510855,"duration":2879}},{"uid":"a445bd9307a8a7d0","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1236//#testresult/a445bd9307a8a7d0","status":"passed","time":{"start":1702430456083,"stop":1702430459180,"duration":3097}},{"uid":"9ff766a12217c6ee","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1232//#testresult/9ff766a12217c6ee","status":"passed","time":{"start":1702366564787,"stop":1702366568073,"duration":3286}},{"uid":"49b9632d5e5bb9eb","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1231//#testresult/49b9632d5e5bb9eb","status":"passed","time":{"start":1702344031180,"stop":1702344034463,"duration":3283}},{"uid":"67d84cbed040e104","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.10/1229//#testresult/67d84cbed040e104","status":"passed","time":{"start":1702257621595,"stop":1702257625468,"duration":3873}}]},"tags":[]},"source":"57abed9e2d3eef53.json","parameterValues":["SouthOxfordshireCouncil","None","None"]}