{"uid":"c2bb6715f8657571","name":"Validate Council Output [SouthOxfordshireCouncil-None-None]","fullName":"features/validate_council_outputs.feature:Validate Council Output","historyId":"7f57931d644fea4dd7a0419f9995c47e","time":{"start":1704709720359,"stop":1704709724498,"duration":4139},"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fd6989fd6d0>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=2084162794\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fd699280720>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fd698f76fd0>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.11/lib/python3.11/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fd6989fd6d0>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=2084162794\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fd6989fd6d0>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=2084162794\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fd699280720>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fd698f76fd0>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.11/lib/python3.11/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fd6989fd6d0>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=2084162794\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","steps":[{"name":"Given the council: SouthOxfordshireCouncil","time":{"start":1704709720359,"stop":1704709720360,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"When we scrape the data from SouthOxfordshireCouncil using None and the None is set","time":{"start":1704709720360,"stop":1704709724498,"duration":4138},"status":"failed","statusMessage":"Error parsing bin data: list index out of range","statusTrace":"ValueError: Error parsing bin data: list index out of range\n","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":0,"hasContent":true,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":2,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"host","value":"fv-az1567-133"},{"name":"thread","value":"2726-MainThread"},{"name":"framework","value":"pytest-bdd"},{"name":"language","value":"cpython3"},{"name":"feature","value":"Test each council output matches expected results"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"council","value":"SouthOxfordshireCouncil"},{"name":"selenium_mode","value":"None"},{"name":"selenium_url","value":"None"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[],"flaky":false}],"history":{"statistic":{"failed":40,"broken":0,"skipped":0,"passed":110,"unknown":0,"total":150},"items":[{"uid":"4699d82ef1032ca5","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1443//#testresult/4699d82ef1032ca5","status":"failed","statusDetails":"ValueError: Error parsing bin data: list index out of range","time":{"start":1704704234969,"stop":1704704239346,"duration":4377}},{"uid":"ec3214eaaf22854a","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1441//#testresult/ec3214eaaf22854a","status":"failed","statusDetails":"ValueError: Error parsing bin data: list index out of range","time":{"start":1704673876943,"stop":1704673881555,"duration":4612}},{"uid":"e8fd63b26da37c0e","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1426//#testresult/e8fd63b26da37c0e","status":"passed","time":{"start":1704615508859,"stop":1704615512033,"duration":3174}},{"uid":"c4ad35f44d7b576a","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1423//#testresult/c4ad35f44d7b576a","status":"passed","time":{"start":1704614893689,"stop":1704614897550,"duration":3861}},{"uid":"7c986d391ac4edd5","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1420//#testresult/7c986d391ac4edd5","status":"passed","time":{"start":1704587597709,"stop":1704587601274,"duration":3565}},{"uid":"bae6d8dcfd232874","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1413//#testresult/bae6d8dcfd232874","status":"passed","time":{"start":1704542867332,"stop":1704542879046,"duration":11714}},{"uid":"752800d412cc950","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1408//#testresult/752800d412cc950","status":"passed","time":{"start":1704496307498,"stop":1704496310747,"duration":3249}},{"uid":"2a6787bec558eb49","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1406//#testresult/2a6787bec558eb49","status":"passed","time":{"start":1704453578926,"stop":1704453583210,"duration":4284}},{"uid":"a1e4f5bb4dc448a6","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1405//#testresult/a1e4f5bb4dc448a6","status":"passed","time":{"start":1704452810616,"stop":1704452813588,"duration":2972}},{"uid":"f15864867684b29e","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1400//#testresult/f15864867684b29e","status":"passed","time":{"start":1704443914910,"stop":1704443918500,"duration":3590}},{"uid":"a17db12a4e9c14a6","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1399//#testresult/a17db12a4e9c14a6","status":"passed","time":{"start":1704443449600,"stop":1704443453462,"duration":3862}},{"uid":"a10c80a1d8423809","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1397//#testresult/a10c80a1d8423809","status":"passed","time":{"start":1704442632467,"stop":1704442635844,"duration":3377}},{"uid":"3988a64b848c490f","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1396//#testresult/3988a64b848c490f","status":"passed","time":{"start":1704442600904,"stop":1704442604940,"duration":4036}},{"uid":"e0dab353b9dc030e","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1390//#testresult/e0dab353b9dc030e","status":"failed","statusDetails":"AssertionError: True","time":{"start":1704417634535,"stop":1704417635746,"duration":1211}},{"uid":"7f031fa15f8ef499","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1379//#testresult/7f031fa15f8ef499","status":"passed","time":{"start":1704406143288,"stop":1704406146813,"duration":3525}},{"uid":"d144d18ce4a866c2","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1378//#testresult/d144d18ce4a866c2","status":"passed","time":{"start":1704406090008,"stop":1704406093347,"duration":3339}},{"uid":"9e390f28f74ab762","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1376//#testresult/9e390f28f74ab762","status":"passed","time":{"start":1704398921015,"stop":1704398925117,"duration":4102}},{"uid":"571fe7b61d7efcf","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1375//#testresult/571fe7b61d7efcf","status":"passed","time":{"start":1704398869812,"stop":1704398873150,"duration":3338}},{"uid":"fbfd0ce9729f23aa","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1373//#testresult/fbfd0ce9729f23aa","status":"passed","time":{"start":1704388432970,"stop":1704388437422,"duration":4452}},{"uid":"1db28bcad122bd10","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1369//#testresult/1db28bcad122bd10","status":"passed","time":{"start":1704378452423,"stop":1704378456103,"duration":3680}}]},"tags":[]},"source":"c2bb6715f8657571.json","parameterValues":["SouthOxfordshireCouncil","None","None"]}