{"uid":"e0336ec94f911849","name":"Validate Council Output [SouthOxfordshireCouncil-None-None]","fullName":"features/validate_council_outputs.feature:Validate Council Output","historyId":"7f57931d644fea4dd7a0419f9995c47e","time":{"start":1703639857542,"stop":1703639862203,"duration":4661},"status":"failed","statusMessage":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fc0febe68d0>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1185266274\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n>                   datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.11.7/x64/lib/python3.11/_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata_string = 'Your usual collection day is different this weekTuesday 2 January 2023'\nformat = '%A %d %B %Y'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\n/opt/hostedtoolcache/Python/3.11.7/x64/lib/python3.11/_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fc0ff948220>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fc0fe7cfd10>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.11/lib/python3.11/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:75: in scrape_step\n    raise (err)\nuk_bin_collection/tests/step_defs/test_validate_council.py:71: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:82: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:69: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:69: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fc0febe68d0>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1185266274\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n                    datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n                bin_type = str.capitalize(bin_info[1].strip())\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:68: ValueError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"status":"failed","statusMessage":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7fc0febe68d0>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1185266274\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n>                   datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.11.7/x64/lib/python3.11/_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndata_string = 'Your usual collection day is different this weekTuesday 2 January 2023'\nformat = '%A %d %B %Y'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\n/opt/hostedtoolcache/Python/3.11.7/x64/lib/python3.11/_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7fc0ff948220>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7fc0fe7cfd10>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.11/lib/python3.11/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:75: in scrape_step\n    raise (err)\nuk_bin_collection/tests/step_defs/test_validate_council.py:71: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:82: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:69: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:69: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7fc0febe68d0>\npage = ''\nkwargs = {'paon': None, 'postcode': None, 'uprn': '10033002851', 'url': 'https://www.southoxon.gov.uk/south-oxfordshire-district-council/recycling-rubbish-and-waste/when-is-your-collection-day/', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=1185266274\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = bin.text.split(\"-\")\n            try:\n                # No date validation since year isn't included on webpage\n                bin_date = get_next_occurrence_from_day_month(\n                    datetime.strptime(bin_info[0].strip() + \" \" + datetime.today().strftime(\"%Y\"),\n                                      \"%A %d %B %Y\")).strftime(date_format)\n                bin_type = str.capitalize(bin_info[1].strip())\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:68: ValueError","steps":[{"name":"Given the council: SouthOxfordshireCouncil","time":{"start":1703639857543,"stop":1703639857543,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"When we scrape the data from SouthOxfordshireCouncil using None and the None is set","time":{"start":1703639857543,"stop":1703639862203,"duration":4660},"status":"failed","statusMessage":"Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","statusTrace":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'\n","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":0,"hasContent":true,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":2,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"host","value":"fv-az849-702"},{"name":"thread","value":"2680-MainThread"},{"name":"framework","value":"pytest-bdd"},{"name":"language","value":"cpython3"},{"name":"feature","value":"Test each council output matches expected results"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"council","value":"SouthOxfordshireCouncil"},{"name":"selenium_mode","value":"None"},{"name":"selenium_url","value":"None"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[],"flaky":false}],"history":{"statistic":{"failed":11,"broken":0,"skipped":0,"passed":86,"unknown":0,"total":97},"items":[{"uid":"72372b4c5be2b178","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1300//#testresult/72372b4c5be2b178","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703553453016,"stop":1703553456945,"duration":3929}},{"uid":"aae29df13d7b4de4","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1298//#testresult/aae29df13d7b4de4","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703541233998,"stop":1703541237015,"duration":3017}},{"uid":"8fae91a931b1cd8a","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1295//#testresult/8fae91a931b1cd8a","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703467242771,"stop":1703467246307,"duration":3536}},{"uid":"b059dfbb20f37f96","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1292//#testresult/b059dfbb20f37f96","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703416548007,"stop":1703416552013,"duration":4006}},{"uid":"fa1dcd000941b902","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1291//#testresult/fa1dcd000941b902","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703416480544,"stop":1703416484660,"duration":4116}},{"uid":"e4bfd4ad32846ee3","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1289//#testresult/e4bfd4ad32846ee3","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703381176097,"stop":1703381180229,"duration":4132}},{"uid":"1f9c6a2843e85e68","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1287//#testresult/1f9c6a2843e85e68","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703294188799,"stop":1703294193219,"duration":4420}},{"uid":"9a3a68cdced7cfdb","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1282//#testresult/9a3a68cdced7cfdb","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703207928230,"stop":1703207932982,"duration":4752}},{"uid":"c625f0c5d5003422","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1281//#testresult/c625f0c5d5003422","status":"failed","statusDetails":"ValueError: Error parsing bin data: time data 'Your usual collection day is different this weekTuesday 2 January 2023' does not match format '%A %d %B %Y'","time":{"start":1703121581212,"stop":1703121584196,"duration":2984}},{"uid":"2bbaf3252c0d2090","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1280//#testresult/2bbaf3252c0d2090","status":"passed","time":{"start":1703034431130,"stop":1703034435671,"duration":4541}},{"uid":"6a128614322ccf9f","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1279//#testresult/6a128614322ccf9f","status":"passed","time":{"start":1703025051885,"stop":1703025055259,"duration":3374}},{"uid":"cfcde4773f639662","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1278//#testresult/cfcde4773f639662","status":"passed","time":{"start":1703025002158,"stop":1703025005508,"duration":3350}},{"uid":"d641028c4dcc0705","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1276//#testresult/d641028c4dcc0705","status":"passed","time":{"start":1702948832223,"stop":1702948836905,"duration":4682}},{"uid":"ba5e9d1b2d3c03af","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1275//#testresult/ba5e9d1b2d3c03af","status":"passed","time":{"start":1702862444348,"stop":1702862448101,"duration":3753}},{"uid":"292a582e18da6d66","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1274//#testresult/292a582e18da6d66","status":"passed","time":{"start":1702860089507,"stop":1702860092853,"duration":3346}},{"uid":"d7cc32248bbb3896","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1272//#testresult/d7cc32248bbb3896","status":"passed","time":{"start":1702843662504,"stop":1702843666759,"duration":4255}},{"uid":"c0c52df3165701ba","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1270//#testresult/c0c52df3165701ba","status":"passed","time":{"start":1702809483456,"stop":1702809486507,"duration":3051}},{"uid":"f52b99a31b7bafe8","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1247//#testresult/f52b99a31b7bafe8","status":"passed","time":{"start":1702657334168,"stop":1702657338193,"duration":4025}},{"uid":"81c775eebb6cd695","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1248//#testresult/81c775eebb6cd695","status":"passed","time":{"start":1702657329881,"stop":1702657333007,"duration":3126}},{"uid":"94c12ba8f7e57552","reportUrl":"https://robbrad.github.io/UKBinCollectionData/3.11/1244//#testresult/94c12ba8f7e57552","status":"passed","time":{"start":1702603270116,"stop":1702603273588,"duration":3472}}]},"tags":[]},"source":"e0336ec94f911849.json","parameterValues":["SouthOxfordshireCouncil","None","None"]}